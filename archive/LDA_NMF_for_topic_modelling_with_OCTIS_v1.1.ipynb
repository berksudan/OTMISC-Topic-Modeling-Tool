{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "LDA/NMF for topic modelling with OCTIS.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Tweets preprocessing"
      ],
      "metadata": {
        "id": "l-K8SZ1orVFS"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "install libraries"
      ],
      "metadata": {
        "id": "KZ1X7YKBPMcv"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Data preprocessing for Crisis dataset v1.1\n",
        "\n",
        "# This notebook is created in Google Colab, please change the paths to your file.\n",
        "# Every preprocessing method is seperate. You can choose the ones that you need. \n",
        "# Write me a note if something goes wrong or you need some new preprocessing methods.\n",
        "\n",
        "# Update from v1.0:\n",
        "# Include crisis_dataset_1\n",
        "# Include evaluation\n",
        "\n",
        "# Enjoy!"
      ],
      "metadata": {
        "id": "XGK58hhta7PI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "G7rkLDWfzttO",
        "outputId": "78e3ff2d-3c66-4c83-de85-d6206ce7a55e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install contractions"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "b6sqi26SsYUM",
        "outputId": "3055700a-9a77-45d4-aa74-0e34c59b29b2"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting contractions\n",
            "  Downloading contractions-0.1.72-py2.py3-none-any.whl (8.3 kB)\n",
            "Collecting textsearch>=0.0.21\n",
            "  Downloading textsearch-0.0.21-py2.py3-none-any.whl (7.5 kB)\n",
            "Collecting anyascii\n",
            "  Downloading anyascii-0.3.1-py3-none-any.whl (287 kB)\n",
            "\u001b[K     |████████████████████████████████| 287 kB 14.9 MB/s \n",
            "\u001b[?25hCollecting pyahocorasick\n",
            "  Downloading pyahocorasick-1.4.4-cp37-cp37m-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (106 kB)\n",
            "\u001b[K     |████████████████████████████████| 106 kB 63.8 MB/s \n",
            "\u001b[?25hInstalling collected packages: pyahocorasick, anyascii, textsearch, contractions\n",
            "Successfully installed anyascii-0.3.1 contractions-0.1.72 pyahocorasick-1.4.4 textsearch-0.0.21\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import unicodedata\n",
        "import re\n",
        "import contractions\n",
        "from pathlib import Path\n",
        "import numpy as np\n",
        "\n",
        "import nltk\n",
        "from nltk.tokenize import word_tokenize\n",
        "from nltk.corpus import stopwords\n",
        "from nltk.stem import WordNetLemmatizer\n",
        "\n",
        "nltk.download('punkt')\n",
        "nltk.download('stopwords')\n",
        "nltk.download('wordnet')\n",
        "nltk.download('omw-1.4')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZiUzg8JzrZ28",
        "outputId": "5490b30e-72e0-4267-9e79-d3277e15304c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Unzipping tokenizers/punkt.zip.\n",
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/stopwords.zip.\n",
            "[nltk_data] Downloading package wordnet to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/wordnet.zip.\n",
            "[nltk_data] Downloading package omw-1.4 to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/omw-1.4.zip.\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Load many datasets"
      ],
      "metadata": {
        "id": "AjsvhkaUrnzx"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def split_dataset(tweets_df, seed = 100, TRAIN = 0.8, DEV = 0.1, TEST = 0.1):\n",
        "    # Define the partition of train, dev and test set, make sure they sum up to 1\n",
        "    PT_TRAIN = TRAIN\n",
        "    PT_DEV = DEV\n",
        "    PT_TEST = TEST\n",
        "\n",
        "    # Define train, dev and test set\n",
        "    tweets_df.loc[: tweets_df.shape[0] * PT_TRAIN, 'partition'] = 'train'\n",
        "    tweets_df.loc[tweets_df.shape[0] * PT_TRAIN : tweets_df.shape[0] * (PT_TRAIN + PT_DEV), 'partition'] = 'dev'\n",
        "    tweets_df.loc[tweets_df.shape[0] * (PT_TRAIN + PT_DEV) : tweets_df.shape[0] - 1, 'partition'] = 'test'\n",
        "\n",
        "    # Shuffle\n",
        "    final_df = tweets_df.sample(frac=1, random_state = seed).reset_index(drop=True)\n",
        "\n",
        "    return final_df"
      ],
      "metadata": {
        "id": "q1ClCwRoRTna"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def load_documents(dataset_dir: str, dataset_text_col: str):\n",
        "   # This method comes from Berk's work: src/utils.py\n",
        "   # Input:\n",
        "   # dataset_dir: The folder where the datasets are stored.\n",
        "   # dataset_text_col: The name of the column that contains tweets.\n",
        "   # (For dataset 1: tweets_text, for dataset 12: text)\n",
        "\n",
        "   # Output:\n",
        "   # One dataframe containing all the data\n",
        "\n",
        "   dataset_data_paths = sorted([path for path in Path(dataset_dir).iterdir() if path.suffix in {'.csv', '.tsv'}])\n",
        "   \n",
        "   dfs = []\n",
        "   labels_as_filenames = []\n",
        "   topic_num = 0\n",
        "   for data_path in dataset_data_paths:\n",
        "      csv_delimiter = '\\t' if data_path.suffix == '.tsv' else ','\n",
        "      df = pd.read_csv(data_path, delimiter=csv_delimiter)\n",
        "      df = df[[dataset_text_col]]\n",
        "      splitted_df = split_dataset(df)\n",
        "      splitted_df.loc[:, 'Topics'] = f'{topic_num}'\n",
        "      topic_num += 1\n",
        "      # Why do we need this?\n",
        "      labels_as_filenames.extend([Path(data_path).stem] * len(df))\n",
        "      dfs.append(splitted_df)\n",
        "   \n",
        "   merged_df = pd.concat(dfs, axis=0)\n",
        "   merged_df.rename(columns={f'{dataset_text_col}':'Tweets'},inplace=True)\n",
        "\n",
        "   return merged_df\n",
        "   #assert False"
      ],
      "metadata": {
        "id": "H_uJ1tF8rnOp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Select the right dataset\n",
        "\n",
        "# Crisis dataset No.1\n",
        "#dataset_dir = '/content/drive/MyDrive/SS_2022_Praktikum/Crisis Dataset/Dataset_1_original'\n",
        "#save_dir = '/content/drive/MyDrive/SS_2022_Praktikum/Crisis Dataset/Dataset_1'\n",
        "#tweets_df = load_documents(dataset_dir, 'tweet_text')\n",
        "#NUM_TOPICS = 11\n",
        "\n",
        "# Crisis dataset No.12\n",
        "dataset_dir = '/content/drive/MyDrive/SS_2022_Praktikum/Crisis Dataset/Dataset_12_original'\n",
        "save_dir = '/content/drive/MyDrive/SS_2022_Praktikum/Crisis Dataset/Dataset_12'\n",
        "tweets_df = load_documents(dataset_dir, 'text')\n",
        "NUM_TOPICS = 4"
      ],
      "metadata": {
        "id": "EuPm7NzrsP9V"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "tweets_df"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 424
        },
        "id": "Bq_qt59Xv0qQ",
        "outputId": "be551589-105a-4326-989a-be2922e14a67"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                                                 Tweets partition Topics\n",
              "0     Bay Area niggas jus felt that lil earthquake l...     train      0\n",
              "1           jswartz Yea! Welcome to earthquake twitter!     train      0\n",
              "2     I think that was a light earthquake, but I won...     train      0\n",
              "3                     Did y  all feel that earthquake?      train      0\n",
              "4     Another freaking #earthquake ... what gives?! ...     train      0\n",
              "...                                                 ...       ...    ...\n",
              "1995  Malcolm Turnbull has praised technology for an...      test      3\n",
              "1996  #NEWS #Cyclone Cyclone Debbie: What will happe...      test      3\n",
              "1997  Watch Tropical Cyclone Debbie intensify from s...      test      3\n",
              "1998  Cyclone dumps bull shark in middle of road htt...     train      3\n",
              "1999  Ocean Sciences Article of the Day - Cyclone De...     train      3\n",
              "\n",
              "[8000 rows x 3 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-3ee042c0-066a-4c6e-8a17-6f3813f54b1f\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Tweets</th>\n",
              "      <th>partition</th>\n",
              "      <th>Topics</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>Bay Area niggas jus felt that lil earthquake l...</td>\n",
              "      <td>train</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>jswartz Yea! Welcome to earthquake twitter!</td>\n",
              "      <td>train</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>I think that was a light earthquake, but I won...</td>\n",
              "      <td>train</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>Did y  all feel that earthquake?</td>\n",
              "      <td>train</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>Another freaking #earthquake ... what gives?! ...</td>\n",
              "      <td>train</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1995</th>\n",
              "      <td>Malcolm Turnbull has praised technology for an...</td>\n",
              "      <td>test</td>\n",
              "      <td>3</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1996</th>\n",
              "      <td>#NEWS #Cyclone Cyclone Debbie: What will happe...</td>\n",
              "      <td>test</td>\n",
              "      <td>3</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1997</th>\n",
              "      <td>Watch Tropical Cyclone Debbie intensify from s...</td>\n",
              "      <td>test</td>\n",
              "      <td>3</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1998</th>\n",
              "      <td>Cyclone dumps bull shark in middle of road htt...</td>\n",
              "      <td>train</td>\n",
              "      <td>3</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1999</th>\n",
              "      <td>Ocean Sciences Article of the Day - Cyclone De...</td>\n",
              "      <td>train</td>\n",
              "      <td>3</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>8000 rows × 3 columns</p>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-3ee042c0-066a-4c6e-8a17-6f3813f54b1f')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-3ee042c0-066a-4c6e-8a17-6f3813f54b1f button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-3ee042c0-066a-4c6e-8a17-6f3813f54b1f');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "'''\n",
        "# Former method\n",
        "\n",
        "path1 = '/content/drive/MyDrive/SS_2022_Praktikum/Crisis Dataset/Dataset_12/earthquakes_eyewitness_crowdflower_2000.tsv'\n",
        "path2 = '/content/drive/MyDrive/SS_2022_Praktikum/Crisis Dataset/Dataset_12/floods_eyewitness_crowdflower_2000.tsv'\n",
        "path3 = '/content/drive/MyDrive/SS_2022_Praktikum/Crisis Dataset/Dataset_12/forestfires_eyewitness_crowdflower_2000.tsv'\n",
        "path4 = '/content/drive/MyDrive/SS_2022_Praktikum/Crisis Dataset/Dataset_12/hurricanes_eyewitness_crowdflower_2000.tsv'\n",
        "\n",
        "tweets_df1=pd.read_csv(path1, sep=\"\\t\")\n",
        "tweets_df2=pd.read_csv(path2, sep=\"\\t\")\n",
        "tweets_df3=pd.read_csv(path3, sep=\"\\t\")\n",
        "tweets_df4=pd.read_csv(path4, sep=\"\\t\")\n",
        "\n",
        "tweets_df1 = tweets_df1[['text']]\n",
        "tweets_df2 = tweets_df2[['text']]\n",
        "tweets_df3 = tweets_df3[['text']]\n",
        "tweets_df4 = tweets_df4[['text']]\n",
        "\n",
        "tweets_df1.rename(columns={'text':'Tweets'},inplace=True)\n",
        "tweets_df2.rename(columns={'text':'Tweets'},inplace=True)\n",
        "tweets_df3.rename(columns={'text':'Tweets'},inplace=True)\n",
        "tweets_df4.rename(columns={'text':'Tweets'},inplace=True)\n",
        "\n",
        "# Give the topic\n",
        "tweets_df1.loc[:, 'Topics'] = 'earthquakes'\n",
        "tweets_df2.loc[:, 'Topics'] = 'floods'\n",
        "tweets_df3.loc[:, 'Topics'] = 'forestfires'\n",
        "tweets_df4.loc[:, 'Topics'] = 'hurricanes'\n",
        "\n",
        "# Concatenate\n",
        "tweets_df = tweets_df1\n",
        "tweets_df = tweets_df.append(tweets_df2, ignore_index = True)\n",
        "tweets_df = tweets_df.append(tweets_df3, ignore_index = True)\n",
        "tweets_df = tweets_df.append(tweets_df4, ignore_index = True)\n",
        "\n",
        "# Shuffle\n",
        "tweets_df = tweets_df.sample(frac=1.0, random_state = 100).reset_index(drop=True)\n",
        "\n",
        "'''"
      ],
      "metadata": {
        "id": "UR63O8znsoOn",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 175
        },
        "outputId": "f44749f6-c147-4877-a9a3-fbe4cb91085a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'\\n# Former method\\n\\npath1 = \\'/content/drive/MyDrive/SS_2022_Praktikum/Crisis Dataset/Dataset_12/earthquakes_eyewitness_crowdflower_2000.tsv\\'\\npath2 = \\'/content/drive/MyDrive/SS_2022_Praktikum/Crisis Dataset/Dataset_12/floods_eyewitness_crowdflower_2000.tsv\\'\\npath3 = \\'/content/drive/MyDrive/SS_2022_Praktikum/Crisis Dataset/Dataset_12/forestfires_eyewitness_crowdflower_2000.tsv\\'\\npath4 = \\'/content/drive/MyDrive/SS_2022_Praktikum/Crisis Dataset/Dataset_12/hurricanes_eyewitness_crowdflower_2000.tsv\\'\\n\\ntweets_df1=pd.read_csv(path1, sep=\"\\t\")\\ntweets_df2=pd.read_csv(path2, sep=\"\\t\")\\ntweets_df3=pd.read_csv(path3, sep=\"\\t\")\\ntweets_df4=pd.read_csv(path4, sep=\"\\t\")\\n\\ntweets_df1 = tweets_df1[[\\'text\\']]\\ntweets_df2 = tweets_df2[[\\'text\\']]\\ntweets_df3 = tweets_df3[[\\'text\\']]\\ntweets_df4 = tweets_df4[[\\'text\\']]\\n\\ntweets_df1.rename(columns={\\'text\\':\\'Tweets\\'},inplace=True)\\ntweets_df2.rename(columns={\\'text\\':\\'Tweets\\'},inplace=True)\\ntweets_df3.rename(columns={\\'text\\':\\'Tweets\\'},inplace=True)\\ntweets_df4.rename(columns={\\'text\\':\\'Tweets\\'},inplace=True)\\n\\n# Give the topic\\ntweets_df1.loc[:, \\'Topics\\'] = \\'earthquakes\\'\\ntweets_df2.loc[:, \\'Topics\\'] = \\'floods\\'\\ntweets_df3.loc[:, \\'Topics\\'] = \\'forestfires\\'\\ntweets_df4.loc[:, \\'Topics\\'] = \\'hurricanes\\'\\n\\n# Concatenate\\ntweets_df = tweets_df1\\ntweets_df = tweets_df.append(tweets_df2, ignore_index = True)\\ntweets_df = tweets_df.append(tweets_df3, ignore_index = True)\\ntweets_df = tweets_df.append(tweets_df4, ignore_index = True)\\n\\n# Shuffle\\ntweets_df = tweets_df.sample(frac=1.0, random_state = 100).reset_index(drop=True)\\n\\n'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Shuffle again\n",
        "tweets_df = tweets_df.sample(frac=1.0, random_state = 100).reset_index(drop=True)"
      ],
      "metadata": {
        "id": "UNcGev2VVqFH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# See if the partition is correct\n",
        "tweets_df.partition.value_counts()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8Wd6gGgLHrIy",
        "outputId": "c0073f0e-7c44-4067-f415-6d2093034360"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "train    6400\n",
              "test      800\n",
              "dev       800\n",
              "Name: partition, dtype: int64"
            ]
          },
          "metadata": {},
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Uncomment to see the merged (or unmerged) dataframes\n",
        "tweets_df"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 424
        },
        "id": "Dqd3T_BtcXyb",
        "outputId": "8dca2603-97b3-44da-ce29-1b6b35e8bfcb"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                                                 Tweets partition Topics\n",
              "0     NASA Sees #Tropical #Cyclone #Debbie Approachi...     train      3\n",
              "1                      A small earthquake just happened     train      0\n",
              "2     'Unprecedented' Wildfires Break Out in Norther...      test      2\n",
              "3                       earthquake in #Oakland just now     train      0\n",
              "4     I don  t know if my heart was beating too fast...     train      0\n",
              "...                                                 ...       ...    ...\n",
              "7995                       Go Dubs #earthquake #bayarea       dev      0\n",
              "7996  Guess this explains why my last apartment cons...     train      1\n",
              "7997  Climatologist explains why 'the conditions are...     train      2\n",
              "7998  i could've had my braces off today but debbie ...     train      3\n",
              "7999  Well, there are a lot of white people in Calif...     train      2\n",
              "\n",
              "[8000 rows x 3 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-1b10b88a-3e8f-4da4-ba4c-17eb43f8529d\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Tweets</th>\n",
              "      <th>partition</th>\n",
              "      <th>Topics</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>NASA Sees #Tropical #Cyclone #Debbie Approachi...</td>\n",
              "      <td>train</td>\n",
              "      <td>3</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>A small earthquake just happened</td>\n",
              "      <td>train</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>'Unprecedented' Wildfires Break Out in Norther...</td>\n",
              "      <td>test</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>earthquake in #Oakland just now</td>\n",
              "      <td>train</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>I don  t know if my heart was beating too fast...</td>\n",
              "      <td>train</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7995</th>\n",
              "      <td>Go Dubs #earthquake #bayarea</td>\n",
              "      <td>dev</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7996</th>\n",
              "      <td>Guess this explains why my last apartment cons...</td>\n",
              "      <td>train</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7997</th>\n",
              "      <td>Climatologist explains why 'the conditions are...</td>\n",
              "      <td>train</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7998</th>\n",
              "      <td>i could've had my braces off today but debbie ...</td>\n",
              "      <td>train</td>\n",
              "      <td>3</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7999</th>\n",
              "      <td>Well, there are a lot of white people in Calif...</td>\n",
              "      <td>train</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>8000 rows × 3 columns</p>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-1b10b88a-3e8f-4da4-ba4c-17eb43f8529d')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-1b10b88a-3e8f-4da4-ba4c-17eb43f8529d button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-1b10b88a-3e8f-4da4-ba4c-17eb43f8529d');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Make sure you run this one before other methods!\n",
        "\n",
        "def to_lowercase(text):\n",
        "    return text.lower()\n",
        "\n",
        "#testing the function on a single sample for explaination\n",
        "print(to_lowercase('IN CHINESE WE CALL CAPITALIZATION AS BIG WRITTING, IN GERMAN AS WELL.'))\n",
        "\n",
        "#converting every row of the column into lower case \n",
        "tweets_df.Tweets=tweets_df.Tweets.apply(to_lowercase)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_w7dSsootJAL",
        "outputId": "62905e52-ea56-4aac-d021-9d8a97d22c0e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "in chinese we call capitalization as big writting, in german as well.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def standardize_accented_chars(text):\n",
        "    return unicodedata.normalize('NFKD', text).encode('ascii', 'ignore').decode('utf-8', 'ignore')\n",
        "\n",
        "#testing the function on a single sample for explaination\n",
        "print(standardize_accented_chars('sómě words such as résumé, café, prótest, divorcé, coördinate, exposé, latté.'))\n",
        "\n",
        "#standardizing accented characters for every row\n",
        "tweets_df.Tweets=tweets_df.Tweets.apply(standardize_accented_chars)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iSDEBSOvhIvC",
        "outputId": "35a4a0de-3985-4d3b-8c8b-1c5d53e80d31"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "some words such as resume, cafe, protest, divorce, coordinate, expose, latte.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Not a method, just to check how many tweets contain urls\n",
        "\n",
        "def get_number_of_urls(documents):\n",
        "    print(\"{:.2f}% of documents contain urls\".format(sum\n",
        "(documents.apply(lambda x:x.find('http'))>0)/len\n",
        "(documents)*100))\n",
        "\n",
        "# Passing the 'Tweets' column of the dataframe as the argument\n",
        "print(get_number_of_urls(tweets_df.Tweets)) "
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jDI0GypOuaAk",
        "outputId": "2f9b42cf-cc41-4577-ad8d-861d1cd6f5c6"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "57.98% of documents contain urls\n",
            "None\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def remove_url(text):\n",
        "    return re.sub(r'https?:\\S*', '', text)\n",
        "\n",
        "#testing the function on a single sample for explaination\n",
        "print(remove_url('using https://www.google.com/ as an example'))\n",
        "\n",
        "#removing urls from every row\n",
        "tweets_df.Tweets=tweets_df.Tweets.apply(remove_url)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8CC5YGzeuo6j",
        "outputId": "23d5022c-f3e8-45ba-f1aa-2b2149a961c6"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "using  as an example\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def expand_contractions(text):\n",
        "    expanded_words = [] \n",
        "    for word in text.split():\n",
        "       expanded_words.append(contractions.fix(word)) \n",
        "    return ' '.join(expanded_words)\n",
        "\n",
        "#testing the function on a single sample for explaination\n",
        "print(expand_contractions(\"Don't is the same as do not\"))\n",
        "\n",
        "#expanding contractions for every row\n",
        "tweets_df.Tweets=tweets_df.Tweets.apply(expand_contractions)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uMXOG8d7uz5B",
        "outputId": "80cf0fd7-0b84-4f62-b475-529ed23b0447"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Do not is the same as do not\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def remove_mentions_and_tags(text):\n",
        "    text = re.sub(r'@\\S*', '', text)\n",
        "    return re.sub(r'#\\S*', '', text)\n",
        "\n",
        "#testing the function on a single sample for explaination\n",
        "print(remove_mentions_and_tags('Some random @abc and #def'))\n",
        "\n",
        "#removing mentions and tags from every row\n",
        "tweets_df.Tweets=tweets_df.Tweets.apply(remove_mentions_and_tags)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Zt4MYvt6vZ2i",
        "outputId": "275b0a84-447c-487a-92c3-b6b961749bf6"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Some random  and \n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def keep_only_alphabet(text):\n",
        "    return re.sub(r'[^a-zA-Z]', ' ', text)\n",
        "\n",
        "#testing the function on a single sample for explaination\n",
        "print(keep_only_alphabet('Just a bit more $$processing required.Just a bit!!!'))\n",
        "\n",
        "#for all the rows\n",
        "tweets_df.Tweets=tweets_df.Tweets.apply(keep_only_alphabet)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EPNZbplPvugU",
        "outputId": "39efc7bb-712f-4f44-a183-4893f28c8b88"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Just a bit more   processing required Just a bit   \n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def remove_stop_words(text):\n",
        "  \"\"\"\n",
        "  Returns text without stop words\n",
        "  \"\"\"\n",
        "  text = word_tokenize(text)\n",
        "  word_list = []\n",
        "  for word in text:\n",
        "      if word not in stopwords.words('english') and word != 'rt':\n",
        "          word_list.append(word)\n",
        "\n",
        "  return ' '.join(word_list)\n",
        "\n",
        "#testing the function on a single sample for explaination\n",
        "print(remove_stop_words('rt Test this text to see which are stop words.'))\n",
        "\n",
        "#removing stop-words and short words from every row\n",
        "tweets_df.Tweets=tweets_df.Tweets.apply(remove_stop_words)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nsh2oi6NwK2B",
        "outputId": "d0f11938-0d2f-4d68-d79e-51ebb842da28"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Test text see stop words .\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def lemmatize(text):\n",
        "  lemmatizer = WordNetLemmatizer()\n",
        "  text_str = word_tokenize(text)\n",
        "  new_words = []\n",
        "\n",
        "  for word in text_str:\n",
        "    new_words.append(lemmatizer.lemmatize(word))\n",
        "  return ' '.join(new_words)\n",
        "\n",
        "#testing the function on a single sample for explaination\n",
        "print(lemmatize('apples, bananas and pears are common fruits that are eaten by humans.'))\n",
        "\n",
        "#Performing lemmatization on every row\n",
        "tweets_df.Tweets=tweets_df.Tweets.apply(lemmatize)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mjqFnTvXxksF",
        "outputId": "2c9b793f-d0dc-4e65-a14a-cc5ceaf3f7c0"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "apple , banana and pear are common fruit that are eaten by human .\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Delete blank rows to fit OCTIS\n",
        "tweets_df = tweets_df[tweets_df['Tweets'].str.len()>=1]\n",
        "tweets_df.reset_index(inplace=True)\n",
        "\n",
        "# Delete the index column caused by reset_index\n",
        "del tweets_df['index']\n",
        "\n",
        "# Delete tweets that only contain 1 or 2 words\n",
        "for i in range(tweets_df.shape[0]):\n",
        "    if len(tweets_df['Tweets'][i].split()) < 3:\n",
        "        tweets_df.drop(index = i, inplace = True)\n",
        "\n",
        "# (OPTIONAL) Delete tweets using the length of string\n",
        "#tweets_df = tweets_df[tweets_df['Tweets'].str.len()>=20]"
      ],
      "metadata": {
        "id": "jQMVZktFKF3A",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "283a6439-b8b0-41fe-af4a-56303629c1ea"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/pandas/core/frame.py:4913: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  errors=errors,\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Uncomment this to check how the df looks like after running\n",
        "tweets_df"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 424
        },
        "id": "oZaYj9MfhVlS",
        "outputId": "5f932406-d458-43ab-d8aa-ca4e7dde6191"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                                                 Tweets partition Topics\n",
              "0               nasa see approaching landfall nasa aqua     train      3\n",
              "1                             small earthquake happened     train      0\n",
              "2     unprecedented wildfire break northern southern...      test      2\n",
              "4               know heart beating fast felt earthquake     train      0\n",
              "5     cyclone debbie coal mine hopeful reopening soo...       dev      3\n",
              "...                                                 ...       ...    ...\n",
              "7983  turn completely flooded school closed car subm...     train      3\n",
              "7985  guess explains last apartment consistently flo...     train      1\n",
              "7986  climatologist explains condition primed fire c...     train      2\n",
              "7987                    could brace today debbie damage     train      3\n",
              "7988                   well lot white people california     train      2\n",
              "\n",
              "[7306 rows x 3 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-09af0f00-6060-4988-b1d3-0288423115e5\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Tweets</th>\n",
              "      <th>partition</th>\n",
              "      <th>Topics</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>nasa see approaching landfall nasa aqua</td>\n",
              "      <td>train</td>\n",
              "      <td>3</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>small earthquake happened</td>\n",
              "      <td>train</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>unprecedented wildfire break northern southern...</td>\n",
              "      <td>test</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>know heart beating fast felt earthquake</td>\n",
              "      <td>train</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>cyclone debbie coal mine hopeful reopening soo...</td>\n",
              "      <td>dev</td>\n",
              "      <td>3</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7983</th>\n",
              "      <td>turn completely flooded school closed car subm...</td>\n",
              "      <td>train</td>\n",
              "      <td>3</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7985</th>\n",
              "      <td>guess explains last apartment consistently flo...</td>\n",
              "      <td>train</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7986</th>\n",
              "      <td>climatologist explains condition primed fire c...</td>\n",
              "      <td>train</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7987</th>\n",
              "      <td>could brace today debbie damage</td>\n",
              "      <td>train</td>\n",
              "      <td>3</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7988</th>\n",
              "      <td>well lot white people california</td>\n",
              "      <td>train</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>7306 rows × 3 columns</p>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-09af0f00-6060-4988-b1d3-0288423115e5')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-09af0f00-6060-4988-b1d3-0288423115e5 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-09af0f00-6060-4988-b1d3-0288423115e5');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 24
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "tweets_df.reset_index(inplace=True)\n",
        "del tweets_df['index']"
      ],
      "metadata": {
        "id": "0O2eDk-xMaO4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Make dataset and vocabulary for OCTIS"
      ],
      "metadata": {
        "id": "V0GLjzTaWhhh"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Create vocabulary.txt\n",
        "\n",
        "def df_to_vocab(df):\n",
        "    word_list = []\n",
        "    for i in range(df.shape[0]):\n",
        "        text = word_tokenize(df.Tweets[i])\n",
        "        for word in text:\n",
        "            if word not in word_list:\n",
        "                word_list.append(word)\n",
        "    return word_list\n",
        "\n",
        "word_list = df_to_vocab(tweets_df)\n",
        "len(word_list)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HsacAIAOKIrR",
        "outputId": "2bcde342-7681-4665-b356-3ce40c4d8f58"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "9266"
            ]
          },
          "metadata": {},
          "execution_count": 26
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def list_to_vocab(word_list):\n",
        "    txt = open(f\"{save_dir}/vocabulary.txt\", 'w')\n",
        "    for i in range(len(word_list)):\n",
        "        txt.write(word_list[i])\n",
        "        txt.write('\\r\\n')\n",
        "    txt.close()\n",
        "\n",
        "list_to_vocab(word_list)"
      ],
      "metadata": {
        "id": "WwYi6YQpMaZf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "tweets_df.to_csv(f'{save_dir}/corpus_reduced.tsv',\\\n",
        "                 sep = '\\t', index=False, header = None)"
      ],
      "metadata": {
        "id": "WmDCmmc5yU4Z"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "tweets_df.to_csv(f'{save_dir}/corpus_with_header_reduced.tsv',\\\n",
        "                 sep = '\\t', index=False)"
      ],
      "metadata": {
        "id": "8Hf5sBfxWE_R"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Use this as a check point\n",
        "#assert False"
      ],
      "metadata": {
        "id": "eVjQopw4A5z2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# OCTIS Initiation"
      ],
      "metadata": {
        "id": "HiDd1uJzxJbY"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install octis"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "-I6eJMjcxP1b",
        "outputId": "2fc60309-6709-48af-9836-33726740e4ee"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting octis\n",
            "  Downloading octis-1.10.4-py2.py3-none-any.whl (129 kB)\n",
            "\u001b[K     |████████████████████████████████| 129 kB 14.9 MB/s \n",
            "\u001b[?25hCollecting sentence-transformers\n",
            "  Downloading sentence-transformers-2.2.0.tar.gz (79 kB)\n",
            "\u001b[K     |████████████████████████████████| 79 kB 10.0 MB/s \n",
            "\u001b[?25hRequirement already satisfied: matplotlib in /usr/local/lib/python3.7/dist-packages (from octis) (3.2.2)\n",
            "Collecting gensim>=4.0.0\n",
            "  Downloading gensim-4.2.0-cp37-cp37m-manylinux_2_12_x86_64.manylinux2010_x86_64.whl (24.1 MB)\n",
            "\u001b[K     |████████████████████████████████| 24.1 MB 1.7 MB/s \n",
            "\u001b[?25hRequirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from octis) (2.23.0)\n",
            "Requirement already satisfied: numpy>=1.19.1 in /usr/local/lib/python3.7/dist-packages (from octis) (1.21.6)\n",
            "Requirement already satisfied: spacy in /usr/local/lib/python3.7/dist-packages (from octis) (3.3.1)\n",
            "Requirement already satisfied: flask in /usr/local/lib/python3.7/dist-packages (from octis) (1.1.4)\n",
            "Requirement already satisfied: torch in /usr/local/lib/python3.7/dist-packages (from octis) (1.11.0+cu113)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.7/dist-packages (from octis) (1.3.5)\n",
            "Collecting scikit-learn==0.24.2\n",
            "  Downloading scikit_learn-0.24.2-cp37-cp37m-manylinux2010_x86_64.whl (22.3 MB)\n",
            "\u001b[K     |████████████████████████████████| 22.3 MB 1.2 MB/s \n",
            "\u001b[?25hCollecting libsvm\n",
            "  Downloading libsvm-3.23.0.4.tar.gz (170 kB)\n",
            "\u001b[K     |████████████████████████████████| 170 kB 78.0 MB/s \n",
            "\u001b[?25hRequirement already satisfied: nltk in /usr/local/lib/python3.7/dist-packages (from octis) (3.7)\n",
            "Collecting scikit-optimize>=0.8.1\n",
            "  Downloading scikit_optimize-0.9.0-py2.py3-none-any.whl (100 kB)\n",
            "\u001b[K     |████████████████████████████████| 100 kB 10.8 MB/s \n",
            "\u001b[?25hCollecting tomotopy\n",
            "  Downloading tomotopy-0.12.2-cp37-cp37m-manylinux_2_12_x86_64.manylinux2010_x86_64.whl (16.3 MB)\n",
            "\u001b[K     |████████████████████████████████| 16.3 MB 60.0 MB/s \n",
            "\u001b[?25hRequirement already satisfied: joblib>=0.11 in /usr/local/lib/python3.7/dist-packages (from scikit-learn==0.24.2->octis) (1.1.0)\n",
            "Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.7/dist-packages (from scikit-learn==0.24.2->octis) (3.1.0)\n",
            "Requirement already satisfied: scipy>=0.19.1 in /usr/local/lib/python3.7/dist-packages (from scikit-learn==0.24.2->octis) (1.4.1)\n",
            "Requirement already satisfied: smart-open>=1.8.1 in /usr/local/lib/python3.7/dist-packages (from gensim>=4.0.0->octis) (5.2.1)\n",
            "Collecting pyaml>=16.9\n",
            "  Downloading pyaml-21.10.1-py2.py3-none-any.whl (24 kB)\n",
            "Requirement already satisfied: PyYAML in /usr/local/lib/python3.7/dist-packages (from pyaml>=16.9->scikit-optimize>=0.8.1->octis) (3.13)\n",
            "Requirement already satisfied: Jinja2<3.0,>=2.10.1 in /usr/local/lib/python3.7/dist-packages (from flask->octis) (2.11.3)\n",
            "Requirement already satisfied: click<8.0,>=5.1 in /usr/local/lib/python3.7/dist-packages (from flask->octis) (7.1.2)\n",
            "Requirement already satisfied: itsdangerous<2.0,>=0.24 in /usr/local/lib/python3.7/dist-packages (from flask->octis) (1.1.0)\n",
            "Requirement already satisfied: Werkzeug<2.0,>=0.15 in /usr/local/lib/python3.7/dist-packages (from flask->octis) (1.0.1)\n",
            "Requirement already satisfied: MarkupSafe>=0.23 in /usr/local/lib/python3.7/dist-packages (from Jinja2<3.0,>=2.10.1->flask->octis) (2.0.1)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.7/dist-packages (from matplotlib->octis) (0.11.0)\n",
            "Requirement already satisfied: pyparsing!=2.0.4,!=2.1.2,!=2.1.6,>=2.0.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib->octis) (3.0.9)\n",
            "Requirement already satisfied: python-dateutil>=2.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib->octis) (2.8.2)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib->octis) (1.4.3)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.7/dist-packages (from kiwisolver>=1.0.1->matplotlib->octis) (4.1.1)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.7/dist-packages (from python-dateutil>=2.1->matplotlib->octis) (1.15.0)\n",
            "Requirement already satisfied: regex>=2021.8.3 in /usr/local/lib/python3.7/dist-packages (from nltk->octis) (2022.6.2)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.7/dist-packages (from nltk->octis) (4.64.0)\n",
            "Requirement already satisfied: pytz>=2017.3 in /usr/local/lib/python3.7/dist-packages (from pandas->octis) (2022.1)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests->octis) (1.24.3)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests->octis) (3.0.4)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests->octis) (2022.6.15)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests->octis) (2.10)\n",
            "Collecting transformers<5.0.0,>=4.6.0\n",
            "  Downloading transformers-4.20.0-py3-none-any.whl (4.4 MB)\n",
            "\u001b[K     |████████████████████████████████| 4.4 MB 36.1 MB/s \n",
            "\u001b[?25hRequirement already satisfied: torchvision in /usr/local/lib/python3.7/dist-packages (from sentence-transformers->octis) (0.12.0+cu113)\n",
            "Collecting sentencepiece\n",
            "  Downloading sentencepiece-0.1.96-cp37-cp37m-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.2 MB)\n",
            "\u001b[K     |████████████████████████████████| 1.2 MB 54.7 MB/s \n",
            "\u001b[?25hCollecting huggingface-hub\n",
            "  Downloading huggingface_hub-0.7.0-py3-none-any.whl (86 kB)\n",
            "\u001b[K     |████████████████████████████████| 86 kB 7.0 MB/s \n",
            "\u001b[?25hRequirement already satisfied: filelock in /usr/local/lib/python3.7/dist-packages (from transformers<5.0.0,>=4.6.0->sentence-transformers->octis) (3.7.1)\n",
            "Collecting tokenizers!=0.11.3,<0.13,>=0.11.1\n",
            "  Downloading tokenizers-0.12.1-cp37-cp37m-manylinux_2_12_x86_64.manylinux2010_x86_64.whl (6.6 MB)\n",
            "\u001b[K     |████████████████████████████████| 6.6 MB 46.7 MB/s \n",
            "\u001b[?25hCollecting PyYAML\n",
            "  Downloading PyYAML-6.0-cp37-cp37m-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_12_x86_64.manylinux2010_x86_64.whl (596 kB)\n",
            "\u001b[K     |████████████████████████████████| 596 kB 58.2 MB/s \n",
            "\u001b[?25hRequirement already satisfied: importlib-metadata in /usr/local/lib/python3.7/dist-packages (from transformers<5.0.0,>=4.6.0->sentence-transformers->octis) (4.11.4)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.7/dist-packages (from transformers<5.0.0,>=4.6.0->sentence-transformers->octis) (21.3)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata->transformers<5.0.0,>=4.6.0->sentence-transformers->octis) (3.8.0)\n",
            "Requirement already satisfied: thinc<8.1.0,>=8.0.14 in /usr/local/lib/python3.7/dist-packages (from spacy->octis) (8.0.17)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.7/dist-packages (from spacy->octis) (57.4.0)\n",
            "Requirement already satisfied: blis<0.8.0,>=0.4.0 in /usr/local/lib/python3.7/dist-packages (from spacy->octis) (0.7.7)\n",
            "Requirement already satisfied: srsly<3.0.0,>=2.4.3 in /usr/local/lib/python3.7/dist-packages (from spacy->octis) (2.4.3)\n",
            "Requirement already satisfied: typer<0.5.0,>=0.3.0 in /usr/local/lib/python3.7/dist-packages (from spacy->octis) (0.4.1)\n",
            "Requirement already satisfied: catalogue<2.1.0,>=2.0.6 in /usr/local/lib/python3.7/dist-packages (from spacy->octis) (2.0.7)\n",
            "Requirement already satisfied: pathy>=0.3.5 in /usr/local/lib/python3.7/dist-packages (from spacy->octis) (0.6.1)\n",
            "Requirement already satisfied: spacy-loggers<2.0.0,>=1.0.0 in /usr/local/lib/python3.7/dist-packages (from spacy->octis) (1.0.2)\n",
            "Requirement already satisfied: wasabi<1.1.0,>=0.9.1 in /usr/local/lib/python3.7/dist-packages (from spacy->octis) (0.9.1)\n",
            "Requirement already satisfied: murmurhash<1.1.0,>=0.28.0 in /usr/local/lib/python3.7/dist-packages (from spacy->octis) (1.0.7)\n",
            "Requirement already satisfied: spacy-legacy<3.1.0,>=3.0.9 in /usr/local/lib/python3.7/dist-packages (from spacy->octis) (3.0.9)\n",
            "Requirement already satisfied: preshed<3.1.0,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from spacy->octis) (3.0.6)\n",
            "Requirement already satisfied: cymem<2.1.0,>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from spacy->octis) (2.0.6)\n",
            "Requirement already satisfied: pydantic!=1.8,!=1.8.1,<1.9.0,>=1.7.4 in /usr/local/lib/python3.7/dist-packages (from spacy->octis) (1.8.2)\n",
            "Requirement already satisfied: langcodes<4.0.0,>=3.2.0 in /usr/local/lib/python3.7/dist-packages (from spacy->octis) (3.3.0)\n",
            "Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in /usr/local/lib/python3.7/dist-packages (from torchvision->sentence-transformers->octis) (7.1.2)\n",
            "Building wheels for collected packages: libsvm, sentence-transformers\n",
            "  Building wheel for libsvm (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for libsvm: filename=libsvm-3.23.0.4-cp37-cp37m-linux_x86_64.whl size=233369 sha256=2a618fedfdfcf780a1abd31157e1ace9305944e3c4d3b79d3139a44310daa84d\n",
            "  Stored in directory: /root/.cache/pip/wheels/cd/e8/1e/bf95cf256e4d3ffc94289ab508c49d48e34c98220af63e3513\n",
            "  Building wheel for sentence-transformers (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for sentence-transformers: filename=sentence_transformers-2.2.0-py3-none-any.whl size=120747 sha256=1aa6a6cf480a7a2f14486102f070fcf149d8cd2c5128e8c2ec01ade058c4ced6\n",
            "  Stored in directory: /root/.cache/pip/wheels/83/c0/df/b6873ab7aac3f2465aa9144b6b4c41c4391cfecc027c8b07e7\n",
            "Successfully built libsvm sentence-transformers\n",
            "Installing collected packages: PyYAML, tokenizers, huggingface-hub, transformers, sentencepiece, scikit-learn, pyaml, tomotopy, sentence-transformers, scikit-optimize, libsvm, gensim, octis\n",
            "  Attempting uninstall: PyYAML\n",
            "    Found existing installation: PyYAML 3.13\n",
            "    Uninstalling PyYAML-3.13:\n",
            "      Successfully uninstalled PyYAML-3.13\n",
            "  Attempting uninstall: scikit-learn\n",
            "    Found existing installation: scikit-learn 1.0.2\n",
            "    Uninstalling scikit-learn-1.0.2:\n",
            "      Successfully uninstalled scikit-learn-1.0.2\n",
            "  Attempting uninstall: gensim\n",
            "    Found existing installation: gensim 3.6.0\n",
            "    Uninstalling gensim-3.6.0:\n",
            "      Successfully uninstalled gensim-3.6.0\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "yellowbrick 1.4 requires scikit-learn>=1.0.0, but you have scikit-learn 0.24.2 which is incompatible.\u001b[0m\n",
            "Successfully installed PyYAML-6.0 gensim-4.2.0 huggingface-hub-0.7.0 libsvm-3.23.0.4 octis-1.10.4 pyaml-21.10.1 scikit-learn-0.24.2 scikit-optimize-0.9.0 sentence-transformers-2.2.0 sentencepiece-0.1.96 tokenizers-0.12.1 tomotopy-0.12.2 transformers-4.20.0\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.colab-display-data+json": {
              "pip_warning": {
                "packages": [
                  "sklearn"
                ]
              }
            }
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import octis\n",
        "from octis.models.LDA import LDA\n",
        "from octis.models.NMF import NMF\n",
        "from octis.dataset.dataset import Dataset\n",
        "from octis.evaluation_metrics.diversity_metrics import TopicDiversity\n",
        "from octis.evaluation_metrics.coherence_metrics import Coherence\n",
        "import numpy as np"
      ],
      "metadata": {
        "id": "kkZuZyv8xUpU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Save TC and TD\n",
        "TCTD_line = []\n",
        "TCTD_all = []"
      ],
      "metadata": {
        "id": "R4ZEyshodoQh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# OCTIS -- LDA with crisis dataset"
      ],
      "metadata": {
        "id": "khItwfu-x7wb"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "With our own data preprocessing method"
      ],
      "metadata": {
        "id": "leG3tOZk2hhn"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "dataset = Dataset()\n",
        "dataset.load_custom_dataset_from_folder(save_dir)"
      ],
      "metadata": {
        "id": "XmbXYf05yAAY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model = LDA(num_topics=NUM_TOPICS, random_state = 98)  # Create model\n",
        "output_LDA_crisis = model.train_model(dataset) # Train the model"
      ],
      "metadata": {
        "id": "3L9U-DqAyyOf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# See what are in the model output\n",
        "\n",
        "print(*list(output_LDA_crisis.keys()), sep=\"\\n\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1NRAqSSI1Xeo",
        "outputId": "102497a0-4c5d-4711-961a-2638089f2dcb"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "topic-word-matrix\n",
            "topics\n",
            "topic-document-matrix\n",
            "test-topic-document-matrix\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "for t in output_LDA_crisis['topics'][:]:\n",
        "  print(\" \".join(t))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yCZGh9tP1c8i",
        "outputId": "db1cd555-65ba-40f3-f15e-d32629e51838"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "wildfire california flood fort mcmurray canada earthquake canadian fire alberta\n",
            "flood earthquake flash like warning going debbie cyclone right rain\n",
            "earthquake flood wildfire felt california feel people fire like time\n",
            "cyclone debbie ex flood queensland school rain flooding wildfire today\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Initialize metric\n",
        "npmi = Coherence(texts=dataset.get_corpus(), topk=10, measure='c_v')\n",
        "\n",
        "# Initialize metric\n",
        "topic_diversity = TopicDiversity(topk=10)"
      ],
      "metadata": {
        "id": "Ij_71YIi1rDE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Retrieve metrics score\n",
        "topic_diversity_score = topic_diversity.score(output_LDA_crisis)\n",
        "print(\"Topic diversity: \" + str(topic_diversity_score))\n",
        "\n",
        "npmi_score = npmi.score(output_LDA_crisis)\n",
        "print(\"Coherence: \" + str(npmi_score))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qPLZnHpi1uDT",
        "outputId": "98f3cf49-f1e4-427c-b26e-4d96101e33ac"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Topic diversity: 0.675\n",
            "Coherence: 0.3960299577721983\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "TCTD_line.append('Crisis_12')\n",
        "TCTD_line.append('LDA')\n",
        "TCTD_line.append(topic_diversity_score)\n",
        "TCTD_line.append(npmi_score)\n",
        "TCTD_all.append(TCTD_line)\n",
        "TCTD_line = []"
      ],
      "metadata": {
        "id": "UTn7bGu4QcF1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "With OCTIS' data preprocessing method (to do)"
      ],
      "metadata": {
        "id": "yQwHuvHE2mtX"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "'''\n",
        "import os\n",
        "import string\n",
        "from octis.preprocessing.preprocessing import Preprocessing\n",
        "os.chdir(os.path.pardir)\n",
        "\n",
        "# Initialize preprocessing\n",
        "preprocessor = Preprocessing(vocabulary=None, max_features=None,\n",
        "                             remove_punctuation=True, punctuation=string.punctuation,\n",
        "                             lemmatize=True, stopword_list='english',\n",
        "                             min_chars=1, min_words_docs=0)\n",
        "# preprocess\n",
        "dataset = preprocessor.preprocess_dataset(documents_path=r'..\\corpus.txt', labels_path=r'..\\labels.txt')\n",
        "\n",
        "# save the preprocessed dataset\n",
        "dataset.save('hello_dataset')\n",
        "'''"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 122
        },
        "id": "8u6uQu6s2plf",
        "outputId": "8059f6cd-fd47-4b1c-df4d-5384309331d0"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "\"\\nimport os\\nimport string\\nfrom octis.preprocessing.preprocessing import Preprocessing\\nos.chdir(os.path.pardir)\\n\\n# Initialize preprocessing\\npreprocessor = Preprocessing(vocabulary=None, max_features=None,\\n                             remove_punctuation=True, punctuation=string.punctuation,\\n                             lemmatize=True, stopword_list='english',\\n                             min_chars=1, min_words_docs=0)\\n# preprocess\\ndataset = preprocessor.preprocess_dataset(documents_path=r'..\\\\corpus.txt', labels_path=r'..\\\\labels.txt')\\n\\n# save the preprocessed dataset\\ndataset.save('hello_dataset')\\n\""
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 113
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# OCTIS -- LDA with 20News dataset"
      ],
      "metadata": {
        "id": "YmRQU4bE-7Xt"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Define dataset\n",
        "dataset = Dataset()\n",
        "dataset.fetch_dataset(\"20NewsGroup\")"
      ],
      "metadata": {
        "id": "srl5KGO94acd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# The length of testset\n",
        "len(dataset.get_corpus()[13862:])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Y5huyzLhrpN6",
        "outputId": "0bf86d4f-e81f-4bca-9c40-415b602b0246"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "2447"
            ]
          },
          "metadata": {},
          "execution_count": 115
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Create Model\n",
        "model = LDA(num_topics=20, alpha=0.1, random_state = 100)\n",
        "\n",
        "# Train the model\n",
        "output_LDA_20news = model.train_model(dataset) "
      ],
      "metadata": {
        "id": "vtLxy4ry4kKK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for t in output_LDA_20news['topics'][:5]:\n",
        "  print(\" \".join(t))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "n4NEC_sT46sX",
        "outputId": "5577210c-a4c2-4343-fdbb-9491fde2efe0"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "people time make child give religion man day thing word\n",
            "people government gun state law weapon crime criminal kill make\n",
            "people make time blue work ticket hand ground police thing\n",
            "man homosexual make light people good turn leave time gay\n",
            "key chip encryption make clipper post security people law public\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Initialize metric\n",
        "npmi = Coherence(texts=dataset.get_corpus(), topk=10, measure='c_v')\n",
        "\n",
        "# Initialize metric\n",
        "topic_diversity = TopicDiversity(topk=10)"
      ],
      "metadata": {
        "id": "k7mtk_4t49qR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Retrieve metrics score\n",
        "topic_diversity_score = topic_diversity.score(output_LDA_20news)\n",
        "print(\"Topic diversity: \" + str(topic_diversity_score))\n",
        "\n",
        "npmi_score = npmi.score(output_LDA_20news)\n",
        "print(\"Coherence: \" + str(npmi_score))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2YjzJL4_4_pc",
        "outputId": "a1b926ea-35a0-4c58-dcd5-ed4cce5b8236"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Topic diversity: 0.695\n",
            "Coherence: 0.5073820330016738\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "TCTD_line.append('20_news')\n",
        "TCTD_line.append('LDA')\n",
        "TCTD_line.append(topic_diversity_score)\n",
        "TCTD_line.append(npmi_score)\n",
        "TCTD_all.append(TCTD_line)\n",
        "TCTD_line = []"
      ],
      "metadata": {
        "id": "EuHs9nFrRH5g"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# OCTIS -- NMF with crisis dataset"
      ],
      "metadata": {
        "id": "6u4xhVWO6Vrf"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "dataset = Dataset()\n",
        "dataset.load_custom_dataset_from_folder(save_dir)"
      ],
      "metadata": {
        "id": "TwR-zuJj6dFZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model = NMF(num_topics=NUM_TOPICS, random_state = 96)  # Create model\n",
        "output_NMF_crisis = model.train_model(dataset) # Train the model"
      ],
      "metadata": {
        "id": "p3w-U-uuPzR8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for t in output_NMF_crisis['topics'][:]:\n",
        "  print(\" \".join(t))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Paw9wp8qP0R-",
        "outputId": "fd9b6b3e-a4cd-4aff-bc04-23b0fe411753"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "cyclone debbie ex queensland school tropical australia today via rain\n",
            "earthquake flood like felt feel home water first anyone going\n",
            "flood rain flash queensland amp time flooding heavy day warning\n",
            "wildfire california fort mcmurray fire canada smoke northern canadian alberta\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Initialize metric\n",
        "npmi = Coherence(texts=dataset.get_corpus(), topk=10, measure='c_v')\n",
        "\n",
        "# Initialize metric\n",
        "topic_diversity = TopicDiversity(topk=10)"
      ],
      "metadata": {
        "id": "Ldngy-hpP6y4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Retrieve metrics score\n",
        "topic_diversity_score = topic_diversity.score(output_NMF_crisis)\n",
        "print(\"Topic diversity: \" + str(topic_diversity_score))\n",
        "\n",
        "npmi_score = npmi.score(output_NMF_crisis)\n",
        "print(\"Coherence: \" + str(npmi_score))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6J8z5nktP8qz",
        "outputId": "82d054ab-ed87-484f-b309-2e21e959f428"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Topic diversity: 0.925\n",
            "Coherence: 0.4740389662093467\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "TCTD_line.append('Crisis_12')\n",
        "TCTD_line.append('NMF')\n",
        "TCTD_line.append(topic_diversity_score)\n",
        "TCTD_line.append(npmi_score)\n",
        "TCTD_all.append(TCTD_line)\n",
        "TCTD_line = []"
      ],
      "metadata": {
        "id": "_O3oBwxKRNUW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# OCTIS -- NMF with 20News dataset"
      ],
      "metadata": {
        "id": "QKjlr5x3Qe-s"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Define dataset\n",
        "dataset = Dataset()\n",
        "dataset.fetch_dataset(\"20NewsGroup\")"
      ],
      "metadata": {
        "id": "Tuviks0qQk7A"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Create Model\n",
        "model = NMF(num_topics=20, random_state = 100)\n",
        "\n",
        "# Train the model\n",
        "output_NMF_20news = model.train_model(dataset) "
      ],
      "metadata": {
        "id": "GlI2MtL6QpOh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for t in output_NMF_20news['topics'][:5]:\n",
        "  print(\" \".join(t))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "E5b274eeQw5h",
        "outputId": "5b28dbc7-f644-4f08-81c9-0fb3ec05f8c3"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "server include base support send widget subject motif mail source\n",
            "system user list information internet application post run window email\n",
            "system key question atheist post argument exist belief true religion\n",
            "graphic image mail send package format object datum model include\n",
            "government turkish russian administration official support fund american war food\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Initialize metric\n",
        "npmi = Coherence(texts=dataset.get_corpus(), topk=10, measure='c_v')\n",
        "\n",
        "# Initialize metric\n",
        "topic_diversity = TopicDiversity(topk=10)"
      ],
      "metadata": {
        "id": "l77fOHFXRPb2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Retrieve metrics score\n",
        "topic_diversity_score = topic_diversity.score(output_NMF_20news)\n",
        "print(\"Topic diversity: \" + str(topic_diversity_score))\n",
        "\n",
        "npmi_score = npmi.score(output_NMF_20news)\n",
        "print(\"Coherence: \" + str(npmi_score))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lELuVWZFRQ6A",
        "outputId": "715b457a-5e4e-47b7-dc54-bfd85db80ef7"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Topic diversity: 0.695\n",
            "Coherence: 0.5978809563977465\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "TCTD_line.append('20_news')\n",
        "TCTD_line.append('NMF')\n",
        "TCTD_line.append(topic_diversity_score)\n",
        "TCTD_line.append(npmi_score)\n",
        "TCTD_all.append(TCTD_line)\n",
        "TCTD_line = []"
      ],
      "metadata": {
        "id": "haMUEItURQvN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Evaluation"
      ],
      "metadata": {
        "id": "g3sIOB9wBWbY"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# TC and TD\n",
        "col_names_TCTD = (\"Dataset\", \"algorithm\", \"Topic Coherence\", \"Topic Diversity\")\n",
        "TCTD_df = pd.DataFrame(TCTD_all, columns=col_names_TCTD)\n",
        "\n",
        "TCTD_df"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 175
        },
        "id": "jgEuOTy3P5d3",
        "outputId": "600c576d-ccb5-49a1-f935-a47e05c1173e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "     Dataset algorithm  Topic Coherence  Topic Diversity\n",
              "0  Crisis_12       LDA            0.675         0.396030\n",
              "1    20_news       LDA            0.695         0.507382\n",
              "2  Crisis_12       NMF            0.925         0.474039\n",
              "3    20_news       NMF            0.695         0.597881"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-d740abce-c55b-4c66-a63d-0589717d9a35\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Dataset</th>\n",
              "      <th>algorithm</th>\n",
              "      <th>Topic Coherence</th>\n",
              "      <th>Topic Diversity</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>Crisis_12</td>\n",
              "      <td>LDA</td>\n",
              "      <td>0.675</td>\n",
              "      <td>0.396030</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>20_news</td>\n",
              "      <td>LDA</td>\n",
              "      <td>0.695</td>\n",
              "      <td>0.507382</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>Crisis_12</td>\n",
              "      <td>NMF</td>\n",
              "      <td>0.925</td>\n",
              "      <td>0.474039</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>20_news</td>\n",
              "      <td>NMF</td>\n",
              "      <td>0.695</td>\n",
              "      <td>0.597881</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-d740abce-c55b-4c66-a63d-0589717d9a35')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-d740abce-c55b-4c66-a63d-0589717d9a35 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-d740abce-c55b-4c66-a63d-0589717d9a35');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 149
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "a = dataset._Dataset__corpus[0]"
      ],
      "metadata": {
        "id": "dWhSfDJNesh1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "len(dataset.get_labels())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-Wg7WxbVeSA9",
        "outputId": "b31e06f3-0e81-4d57-a4d4-50cdacd9a1dd"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "16309"
            ]
          },
          "metadata": {},
          "execution_count": 135
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Match the number of labels to topics\n",
        "# Adjust according to the output in the block below\n",
        "\n",
        "# Dataset_12\n",
        "in_labels = {0:'earthquake',\n",
        "             1:'floods',\n",
        "             2:'forestfires',\n",
        "             3:'hurricanes'}\n",
        "\n",
        "out_labels = {0:'hurricanes',\n",
        "              1:'earthquake',\n",
        "              2:'floods',\n",
        "              3:'forestfires'}\n",
        "\n",
        "# 20 news dataset (Not accurate, we don't use this for now)\n",
        "#labels_20news = {}\n",
        "#for i in range(20):\n",
        "#    labels_20news[i] = dataset._Dataset__metadata['labels'][i]"
      ],
      "metadata": {
        "id": "Lo3n5i3OemGy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Make 20 news test dataset\n",
        "# testset_20news: The texts\n",
        "# testset_20news_labels: The labels\n",
        "dataset = Dataset()\n",
        "dataset.fetch_dataset(\"20NewsGroup\")\n",
        "\n",
        "testset_20news_orig = dataset.get_corpus()[13862:]\n",
        "testset_20news = []\n",
        "for i in range(len(testset_20news_orig)):\n",
        "    full = ' '.join(s for s in testset_20news_orig[i])\n",
        "    testset_20news.append(full)\n",
        "testset_20news_labels = dataset.get_labels()[13862:]"
      ],
      "metadata": {
        "id": "7VfrEnUix5O5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for t in output_NMF_crisis['topics'][:]:\n",
        "  print(\" \".join(t))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OhjTF2mRfAA4",
        "outputId": "84d94c12-2035-42df-c8f6-57e9cfbee0d8"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "cyclone debbie ex queensland school tropical australia today via rain\n",
            "earthquake flood like felt feel home water first anyone going\n",
            "flood rain flash queensland amp time flooding heavy day warning\n",
            "wildfire california fort mcmurray fire canada smoke northern canadian alberta\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Doc-Topic Output (Only test set here)\n",
        "# Why do we need \"run_id\"\n",
        "# 4 changes to make in total when changing the algorithm (and the corresponding dataset)\n",
        "# 1 change to make when changing the dataset (by commenting)\n",
        "\n",
        "col_names_DT = (\"Document\", \"Real Label\", \"Assigned Topic Num\", \"Assignment Score\")\n",
        "result_DT = []\n",
        "\n",
        "# Dataset 1\n",
        "#df = pd.read_csv('/content/drive/MyDrive/SS_2022_Praktikum/Crisis Dataset/Dataset_1/corpus_with_header.tsv', delimiter='\\t')\n",
        "\n",
        "# Dataset 12\n",
        "df = pd.read_csv('/content/drive/MyDrive/SS_2022_Praktikum/Crisis Dataset/Dataset_12/corpus_with_header.tsv', delimiter='\\t')\n",
        "\n",
        "# Crisis dataset\n",
        "df = df.loc[df['partition'] == 'test']\n",
        "output_max = np.max(output_LDA_crisis['test-topic-document-matrix'], axis = 0)\n",
        "output_index = np.argmax(output_LDA_crisis['test-topic-document-matrix'], axis = 0)\n",
        "length = len(output_max)\n",
        "\n",
        "# 20 news dataset (didn't perform really well here, so we don't use it for now)\n",
        "#length = len(testset_20news)\n",
        "#output_max = np.max(output_NMF_20news['test-topic-document-matrix'], axis = 0)\n",
        "#output_index = np.argmax(output_NMF_20news['test-topic-document-matrix'], axis = 0)\n",
        "\n",
        "for i in range(length):\n",
        "    result_DT_line = []\n",
        "\n",
        "    # Crisis dataset\n",
        "    result_DT_line.append(df[i:i+1].Tweets.values[0])\n",
        "    result_DT_line.append(in_labels[df[i:i+1].Topics.values[0]])\n",
        "\n",
        "    # 20 news dataset\n",
        "    #result_DT_line.append(testset_20news[i])\n",
        "    #result_DT_line.append(testset_20news_labels[i])\n",
        "\n",
        "    result_DT_line.append(output_index[i])\n",
        "    result_DT_line.append(output_max[i])\n",
        "\n",
        "    result_DT.append(result_DT_line)\n",
        "\n",
        "Doc_Topic_df = pd.DataFrame(result_DT, columns=col_names_DT)\n",
        "\n",
        "Doc_Topic_df"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 424
        },
        "id": "xcFr7ROLBaZU",
        "outputId": "6dce7a76-39b4-4a79-8035-6c1d6fac8974"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                                              Document   Real Label  \\\n",
              "0    unprecedented wildfire break northern southern...  forestfires   \n",
              "1    heatwaves flood warning going place thought to...       floods   \n",
              "2                 wildfire devastate northern southern  forestfires   \n",
              "3    uploaded month patreon little earlier case cyc...   hurricanes   \n",
              "4            morrison still extreme wildfire behaviour  forestfires   \n",
              "..                                                 ...          ...   \n",
              "779     see feel like escape hellish bbc vine bbcworld  forestfires   \n",
              "780  earthquake japan shortened day planet earth mi...   earthquake   \n",
              "781  grocery price rise across australia cyclone de...   hurricanes   \n",
              "782  bbcnews pm california wildfire serious usually...  forestfires   \n",
              "783  flash flooding concern ohio valley northeast f...       floods   \n",
              "\n",
              "     Assigned Topic Num  Assignment Score  \n",
              "0                     0          0.700985  \n",
              "1                     1          0.737232  \n",
              "2                     0          0.848227  \n",
              "3                     1          0.662079  \n",
              "4                     0          0.723109  \n",
              "..                  ...               ...  \n",
              "779                   2          0.595913  \n",
              "780                   2          0.618198  \n",
              "781                   3          0.928491  \n",
              "782                   0          0.854030  \n",
              "783                   1          0.613737  \n",
              "\n",
              "[784 rows x 4 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-3803d742-8ff6-4cd2-8427-09ea4a42b52a\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Document</th>\n",
              "      <th>Real Label</th>\n",
              "      <th>Assigned Topic Num</th>\n",
              "      <th>Assignment Score</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>unprecedented wildfire break northern southern...</td>\n",
              "      <td>forestfires</td>\n",
              "      <td>0</td>\n",
              "      <td>0.700985</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>heatwaves flood warning going place thought to...</td>\n",
              "      <td>floods</td>\n",
              "      <td>1</td>\n",
              "      <td>0.737232</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>wildfire devastate northern southern</td>\n",
              "      <td>forestfires</td>\n",
              "      <td>0</td>\n",
              "      <td>0.848227</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>uploaded month patreon little earlier case cyc...</td>\n",
              "      <td>hurricanes</td>\n",
              "      <td>1</td>\n",
              "      <td>0.662079</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>morrison still extreme wildfire behaviour</td>\n",
              "      <td>forestfires</td>\n",
              "      <td>0</td>\n",
              "      <td>0.723109</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>779</th>\n",
              "      <td>see feel like escape hellish bbc vine bbcworld</td>\n",
              "      <td>forestfires</td>\n",
              "      <td>2</td>\n",
              "      <td>0.595913</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>780</th>\n",
              "      <td>earthquake japan shortened day planet earth mi...</td>\n",
              "      <td>earthquake</td>\n",
              "      <td>2</td>\n",
              "      <td>0.618198</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>781</th>\n",
              "      <td>grocery price rise across australia cyclone de...</td>\n",
              "      <td>hurricanes</td>\n",
              "      <td>3</td>\n",
              "      <td>0.928491</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>782</th>\n",
              "      <td>bbcnews pm california wildfire serious usually...</td>\n",
              "      <td>forestfires</td>\n",
              "      <td>0</td>\n",
              "      <td>0.854030</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>783</th>\n",
              "      <td>flash flooding concern ohio valley northeast f...</td>\n",
              "      <td>floods</td>\n",
              "      <td>1</td>\n",
              "      <td>0.613737</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>784 rows × 4 columns</p>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-3803d742-8ff6-4cd2-8427-09ea4a42b52a')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-3803d742-8ff6-4cd2-8427-09ea4a42b52a button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-3803d742-8ff6-4cd2-8427-09ea4a42b52a');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 155
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Method from Berk's work, 3q!\n",
        "# Define length according to the dataset\n",
        "length = 4\n",
        "\n",
        "for i in range(length):\n",
        "    print(f'Topic {i}:')\n",
        "    print(Doc_Topic_df.query(f'`Assigned Topic Num` == {i}') ['Real Label'].value_counts())\n",
        "    print('-'*32)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2kdIkcu0U5qG",
        "outputId": "e9f81439-ff04-4af7-dd59-1dcafeb84fd5"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Topic 0:\n",
            "forestfires    140\n",
            "earthquake      51\n",
            "floods           7\n",
            "hurricanes       3\n",
            "Name: Real Label, dtype: int64\n",
            "--------------------------------\n",
            "Topic 1:\n",
            "floods         143\n",
            "earthquake      27\n",
            "hurricanes      12\n",
            "forestfires      6\n",
            "Name: Real Label, dtype: int64\n",
            "--------------------------------\n",
            "Topic 2:\n",
            "earthquake     64\n",
            "forestfires    43\n",
            "floods         32\n",
            "hurricanes     13\n",
            "Name: Real Label, dtype: int64\n",
            "--------------------------------\n",
            "Topic 3:\n",
            "hurricanes     172\n",
            "earthquake      46\n",
            "floods          17\n",
            "forestfires      8\n",
            "Name: Real Label, dtype: int64\n",
            "--------------------------------\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Topic-Word Output\n",
        "# 1 change to make in total when changing the algorithm (and the corresponding dataset)\n",
        "# 1 change to make when changing the dataset (by commenting)\n",
        "# Remember to change NUM_TOPICS, it's also possible to change it here\n",
        "NUM_TOPICS = 20\n",
        "\n",
        "col_names_TW = (\"num_given_topics\", \"topic_num\", \"topic_words\")\n",
        "result_TW = []\n",
        "\n",
        "for i in range(NUM_TOPICS):\n",
        "    result_TW_line = []\n",
        "\n",
        "    result_TW_line.append(NUM_TOPICS)\n",
        "    result_TW_line.append(i)\n",
        "    result_TW_line.append(output_LDA_20news['topics'][i])\n",
        "    result_TW.append(result_TW_line)\n",
        "\n",
        "Topic_word_df = pd.DataFrame(result_TW, columns=col_names_TW)\n",
        "Topic_word_df"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 676
        },
        "id": "LeMXRw7ANA9c",
        "outputId": "7d1e85dd-972c-4c03-80e2-e0de00e1a359"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "    num_given_topics  topic_num  \\\n",
              "0                 20          0   \n",
              "1                 20          1   \n",
              "2                 20          2   \n",
              "3                 20          3   \n",
              "4                 20          4   \n",
              "5                 20          5   \n",
              "6                 20          6   \n",
              "7                 20          7   \n",
              "8                 20          8   \n",
              "9                 20          9   \n",
              "10                20         10   \n",
              "11                20         11   \n",
              "12                20         12   \n",
              "13                20         13   \n",
              "14                20         14   \n",
              "15                20         15   \n",
              "16                20         16   \n",
              "17                20         17   \n",
              "18                20         18   \n",
              "19                20         19   \n",
              "\n",
              "                                          topic_words  \n",
              "0   [people, time, make, child, give, religion, ma...  \n",
              "1   [people, government, gun, state, law, weapon, ...  \n",
              "2   [people, make, time, blue, work, ticket, hand,...  \n",
              "3   [man, homosexual, make, light, people, good, t...  \n",
              "4   [key, chip, encryption, make, clipper, post, s...  \n",
              "5   [armenian, space, turkish, launch, year, russi...  \n",
              "6   [color, driver, bit, mode, card, run, work, di...  \n",
              "7   [page, title, text, include, information, dept...  \n",
              "8   [file, image, mail, program, information, incl...  \n",
              "9   [win, year, gun, make, team, rate, lose, back,...  \n",
              "10  [drive, card, speed, power, buy, system, compu...  \n",
              "11  [game, play, year, good, team, player, time, m...  \n",
              "12  [window, application, widget, work, resource, ...  \n",
              "13  [price, good, keyboard, list, offer, sale, sel...  \n",
              "14  [water, system, drug, disease, study, make, pl...  \n",
              "15  [problem, work, drive, system, disk, run, conn...  \n",
              "16  [car, cost, make, money, year, tank, gas, engi...  \n",
              "17  [book, question, point, people, belief, good, ...  \n",
              "18  [question, batf, start, find, feel, back, answ...  \n",
              "19  [love, people, hate, jewish, sin, doctor, isra...  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-7c6275bb-c30f-4b19-a7ba-b80af6df6df1\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>num_given_topics</th>\n",
              "      <th>topic_num</th>\n",
              "      <th>topic_words</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>20</td>\n",
              "      <td>0</td>\n",
              "      <td>[people, time, make, child, give, religion, ma...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>20</td>\n",
              "      <td>1</td>\n",
              "      <td>[people, government, gun, state, law, weapon, ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>20</td>\n",
              "      <td>2</td>\n",
              "      <td>[people, make, time, blue, work, ticket, hand,...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>20</td>\n",
              "      <td>3</td>\n",
              "      <td>[man, homosexual, make, light, people, good, t...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>20</td>\n",
              "      <td>4</td>\n",
              "      <td>[key, chip, encryption, make, clipper, post, s...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>20</td>\n",
              "      <td>5</td>\n",
              "      <td>[armenian, space, turkish, launch, year, russi...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>20</td>\n",
              "      <td>6</td>\n",
              "      <td>[color, driver, bit, mode, card, run, work, di...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>20</td>\n",
              "      <td>7</td>\n",
              "      <td>[page, title, text, include, information, dept...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>20</td>\n",
              "      <td>8</td>\n",
              "      <td>[file, image, mail, program, information, incl...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9</th>\n",
              "      <td>20</td>\n",
              "      <td>9</td>\n",
              "      <td>[win, year, gun, make, team, rate, lose, back,...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>10</th>\n",
              "      <td>20</td>\n",
              "      <td>10</td>\n",
              "      <td>[drive, card, speed, power, buy, system, compu...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>11</th>\n",
              "      <td>20</td>\n",
              "      <td>11</td>\n",
              "      <td>[game, play, year, good, team, player, time, m...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>12</th>\n",
              "      <td>20</td>\n",
              "      <td>12</td>\n",
              "      <td>[window, application, widget, work, resource, ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>13</th>\n",
              "      <td>20</td>\n",
              "      <td>13</td>\n",
              "      <td>[price, good, keyboard, list, offer, sale, sel...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>14</th>\n",
              "      <td>20</td>\n",
              "      <td>14</td>\n",
              "      <td>[water, system, drug, disease, study, make, pl...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>15</th>\n",
              "      <td>20</td>\n",
              "      <td>15</td>\n",
              "      <td>[problem, work, drive, system, disk, run, conn...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>16</th>\n",
              "      <td>20</td>\n",
              "      <td>16</td>\n",
              "      <td>[car, cost, make, money, year, tank, gas, engi...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>17</th>\n",
              "      <td>20</td>\n",
              "      <td>17</td>\n",
              "      <td>[book, question, point, people, belief, good, ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>18</th>\n",
              "      <td>20</td>\n",
              "      <td>18</td>\n",
              "      <td>[question, batf, start, find, feel, back, answ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>19</th>\n",
              "      <td>20</td>\n",
              "      <td>19</td>\n",
              "      <td>[love, people, hate, jewish, sin, doctor, isra...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-7c6275bb-c30f-4b19-a7ba-b80af6df6df1')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-7c6275bb-c30f-4b19-a7ba-b80af6df6df1 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-7c6275bb-c30f-4b19-a7ba-b80af6df6df1');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 140
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "word_list.index('window')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SUvUXbLcRLEG",
        "outputId": "f61d334a-2bca-40de-a1d5-503e60c85123"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "614"
            ]
          },
          "metadata": {},
          "execution_count": 141
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "output_LDA_20news['topics']"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "t342xJFJRT6r",
        "outputId": "703d369f-afce-4cfd-942f-b4732e21706a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[['people',\n",
              "  'time',\n",
              "  'make',\n",
              "  'child',\n",
              "  'give',\n",
              "  'religion',\n",
              "  'man',\n",
              "  'day',\n",
              "  'thing',\n",
              "  'word'],\n",
              " ['people',\n",
              "  'government',\n",
              "  'gun',\n",
              "  'state',\n",
              "  'law',\n",
              "  'weapon',\n",
              "  'crime',\n",
              "  'criminal',\n",
              "  'kill',\n",
              "  'make'],\n",
              " ['people',\n",
              "  'make',\n",
              "  'time',\n",
              "  'blue',\n",
              "  'work',\n",
              "  'ticket',\n",
              "  'hand',\n",
              "  'ground',\n",
              "  'police',\n",
              "  'thing'],\n",
              " ['man',\n",
              "  'homosexual',\n",
              "  'make',\n",
              "  'light',\n",
              "  'people',\n",
              "  'good',\n",
              "  'turn',\n",
              "  'leave',\n",
              "  'time',\n",
              "  'gay'],\n",
              " ['key',\n",
              "  'chip',\n",
              "  'encryption',\n",
              "  'make',\n",
              "  'clipper',\n",
              "  'post',\n",
              "  'security',\n",
              "  'people',\n",
              "  'law',\n",
              "  'public'],\n",
              " ['armenian',\n",
              "  'space',\n",
              "  'turkish',\n",
              "  'launch',\n",
              "  'year',\n",
              "  'russian',\n",
              "  'genocide',\n",
              "  'report',\n",
              "  'greek',\n",
              "  'satellite'],\n",
              " ['color',\n",
              "  'driver',\n",
              "  'bit',\n",
              "  'mode',\n",
              "  'card',\n",
              "  'run',\n",
              "  'work',\n",
              "  'display',\n",
              "  'window',\n",
              "  'set'],\n",
              " ['page',\n",
              "  'title',\n",
              "  'text',\n",
              "  'include',\n",
              "  'information',\n",
              "  'depth',\n",
              "  'character',\n",
              "  'program',\n",
              "  'copy',\n",
              "  'year'],\n",
              " ['file',\n",
              "  'image',\n",
              "  'mail',\n",
              "  'program',\n",
              "  'information',\n",
              "  'include',\n",
              "  'send',\n",
              "  'software',\n",
              "  'system',\n",
              "  'list'],\n",
              " ['win',\n",
              "  'year',\n",
              "  'gun',\n",
              "  'make',\n",
              "  'team',\n",
              "  'rate',\n",
              "  'lose',\n",
              "  'back',\n",
              "  'red',\n",
              "  'start'],\n",
              " ['drive',\n",
              "  'card',\n",
              "  'speed',\n",
              "  'power',\n",
              "  'buy',\n",
              "  'system',\n",
              "  'computer',\n",
              "  'bus',\n",
              "  'scsi',\n",
              "  'work'],\n",
              " ['game',\n",
              "  'play',\n",
              "  'year',\n",
              "  'good',\n",
              "  'team',\n",
              "  'player',\n",
              "  'time',\n",
              "  'make',\n",
              "  'season',\n",
              "  'win'],\n",
              " ['window',\n",
              "  'application',\n",
              "  'widget',\n",
              "  'work',\n",
              "  'resource',\n",
              "  'run',\n",
              "  'call',\n",
              "  'program',\n",
              "  'event',\n",
              "  'set'],\n",
              " ['price',\n",
              "  'good',\n",
              "  'keyboard',\n",
              "  'list',\n",
              "  'offer',\n",
              "  'sale',\n",
              "  'sell',\n",
              "  'include',\n",
              "  'make',\n",
              "  'buy'],\n",
              " ['water',\n",
              "  'system',\n",
              "  'drug',\n",
              "  'disease',\n",
              "  'study',\n",
              "  'make',\n",
              "  'planet',\n",
              "  'patient',\n",
              "  'science',\n",
              "  'earth'],\n",
              " ['problem',\n",
              "  'work',\n",
              "  'drive',\n",
              "  'system',\n",
              "  'disk',\n",
              "  'run',\n",
              "  'connect',\n",
              "  'find',\n",
              "  'time',\n",
              "  'software'],\n",
              " ['car',\n",
              "  'cost',\n",
              "  'make',\n",
              "  'money',\n",
              "  'year',\n",
              "  'tank',\n",
              "  'gas',\n",
              "  'engine',\n",
              "  'time',\n",
              "  'hour'],\n",
              " ['book',\n",
              "  'question',\n",
              "  'point',\n",
              "  'people',\n",
              "  'belief',\n",
              "  'good',\n",
              "  'true',\n",
              "  'make',\n",
              "  'read',\n",
              "  'church'],\n",
              " ['question',\n",
              "  'batf',\n",
              "  'start',\n",
              "  'find',\n",
              "  'feel',\n",
              "  'back',\n",
              "  'answer',\n",
              "  'good',\n",
              "  'happen',\n",
              "  'cop'],\n",
              " ['love',\n",
              "  'people',\n",
              "  'hate',\n",
              "  'jewish',\n",
              "  'sin',\n",
              "  'doctor',\n",
              "  'israeli',\n",
              "  'body',\n",
              "  'hospital',\n",
              "  'find']]"
            ]
          },
          "metadata": {},
          "execution_count": 142
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "len(word_list)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2qXwM6A1QKPO",
        "outputId": "8ab44cff-15b9-4d55-ff40-1970904ba55c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "9266"
            ]
          },
          "metadata": {},
          "execution_count": 143
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Test (Delete when finished)"
      ],
      "metadata": {
        "id": "cSMYG-OdOWBq"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "dataset = Dataset()\n",
        "dataset.load_custom_dataset_from_folder(save_dir)\n",
        "# Create Model\n",
        "model = NMF(num_topics=4)\n",
        "\n",
        "# Train the model\n",
        "output = model.train_model(dataset) "
      ],
      "metadata": {
        "id": "dGXVSVkjDezH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Note the 4 outputs:\n",
        "\n",
        "\n",
        "*   *topics*: the list of word topics\n",
        "*   *topic-word-matrix*: the distribution of the words of the vocabulary for each topic (dimensions: |num topics| x |vocabulary|)\n",
        "*   *topic-document-matrix*: the distribution of the topics for each document of the training set (dimensions: |num topics| x |training documents|)\n",
        "*   *test-topic-document-matrix*: the distribution of the topics for each document of the testing set (dimensions: |num topics| x |test documents|)\n"
      ],
      "metadata": {
        "id": "wK4BlqOjMHL7"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(*list(output.keys()), sep=\"\\n\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "h-wZ2-ObIj3d",
        "outputId": "b18d27e6-644e-4274-e589-14f87981db1b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "topic-word-matrix\n",
            "topics\n",
            "topic-document-matrix\n",
            "test-topic-document-matrix\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "#output_LDA_20news\n",
        "output_LDA_20news['test-topic-document-matrix']"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "igzo1sPuIW6V",
        "outputId": "25bcfb54-487a-4deb-c374-49315c330e1a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[0.        , 0.        , 0.        , ..., 0.4209156 , 0.01250645,\n",
              "        0.        ],\n",
              "       [0.        , 0.46702215, 0.        , ..., 0.22719279, 0.0125052 ,\n",
              "        0.44856879],\n",
              "       [0.        , 0.        , 0.        , ..., 0.        , 0.32633793,\n",
              "        0.31227356],\n",
              "       ...,\n",
              "       [0.        , 0.18373396, 0.        , ..., 0.        , 0.0125042 ,\n",
              "        0.        ],\n",
              "       [0.21632406, 0.        , 0.        , ..., 0.        , 0.44857687,\n",
              "        0.        ],\n",
              "       [0.0658233 , 0.        , 0.        , ..., 0.2987439 , 0.01250443,\n",
              "        0.        ]])"
            ]
          },
          "metadata": {},
          "execution_count": 146
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "output['test-topic-document-matrix']\n",
        "output_max = np.max(output['test-topic-document-matrix'], axis = 0)\n",
        "output_index = np.argmax(output['test-topic-document-matrix'], axis = 0)\n",
        "\n",
        "output_index"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fi9HKfCeJQ8X",
        "outputId": "ee94c4cd-e31c-407b-ad55-34bdf64a7cc5"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([2, 3, 2, 0, 2, 1, 2, 2, 2, 1, 1, 0, 3, 1, 0, 3, 1, 2, 1, 3, 2, 3,\n",
              "       2, 2, 1, 3, 2, 1, 1, 2, 3, 0, 3, 3, 3, 3, 0, 1, 0, 1, 0, 0, 1, 3,\n",
              "       0, 1, 3, 2, 2, 0, 3, 2, 1, 0, 0, 2, 0, 2, 3, 3, 1, 3, 1, 1, 3, 2,\n",
              "       2, 1, 2, 2, 1, 2, 2, 1, 0, 2, 0, 1, 1, 1, 0, 3, 0, 3, 0, 3, 3, 3,\n",
              "       3, 0, 0, 1, 3, 3, 1, 1, 0, 2, 0, 3, 3, 3, 1, 1, 1, 1, 1, 1, 2, 3,\n",
              "       3, 0, 2, 0, 2, 0, 0, 0, 3, 3, 1, 2, 3, 1, 0, 1, 2, 3, 1, 0, 0, 0,\n",
              "       1, 0, 2, 2, 3, 3, 2, 0, 2, 0, 1, 2, 2, 0, 3, 3, 1, 0, 2, 3, 0, 3,\n",
              "       3, 3, 3, 3, 1, 1, 2, 2, 1, 1, 3, 3, 2, 3, 0, 3, 0, 3, 3, 2, 3, 1,\n",
              "       0, 2, 0, 0, 2, 1, 3, 1, 0, 0, 1, 2, 3, 0, 0, 2, 0, 2, 0, 3, 3, 0,\n",
              "       3, 1, 3, 0, 2, 2, 1, 3, 3, 3, 1, 0, 0, 0, 0, 2, 0, 1, 1, 3, 0, 1,\n",
              "       3, 1, 3, 0, 2, 1, 0, 1, 0, 3, 1, 2, 1, 0, 0, 1, 2, 3, 2, 3, 0, 3,\n",
              "       1, 0, 0, 0, 3, 3, 1, 3, 0, 1, 1, 2, 2, 0, 2, 1, 1, 1, 1, 2, 3, 2,\n",
              "       3, 1, 0, 0, 3, 0, 0, 2, 1, 3, 3, 0, 1, 3, 3, 0, 3, 0, 1, 3, 2, 3,\n",
              "       3, 0, 3, 1, 1, 3, 2, 1, 0, 2, 1, 3, 2, 0, 0, 3, 3, 3, 2, 2, 0, 1,\n",
              "       1, 1, 3, 1, 2, 1, 1, 1, 3, 2, 1, 0, 0, 1, 0, 2, 2, 2, 1, 2, 1, 3,\n",
              "       2, 3, 0, 0, 3, 1, 0, 3, 1, 0, 2, 2, 1, 1, 2, 0, 2, 1, 0, 0, 3, 2,\n",
              "       3, 0, 2, 0, 1, 1, 2, 2, 3, 2, 2, 0, 2, 1, 1, 2, 2, 1, 3, 1, 3, 1,\n",
              "       0, 2, 1, 3, 0, 1, 1, 2, 3, 2, 0, 2, 2, 0, 1, 0, 0, 3, 2, 1, 3, 0,\n",
              "       1, 3, 3, 0, 0, 3, 3, 3, 3, 1, 3, 2, 1, 3, 3, 3, 2, 3, 3, 0, 0, 2,\n",
              "       0, 3, 2, 1, 2, 2, 3, 1, 3, 0, 2, 2, 2, 0, 0, 3, 1, 2, 3, 0, 0, 1,\n",
              "       0, 1, 3, 3, 0, 2, 3, 1, 3, 0, 2, 2, 3, 2, 1, 0, 0, 3, 3, 0, 0, 2,\n",
              "       1, 3, 1, 3, 1, 2, 3, 0, 0, 3, 3, 2, 3, 2, 2, 1, 3, 3, 1, 1, 2, 2,\n",
              "       0, 0, 3, 1, 3, 2, 3, 3, 2, 3, 3, 2, 2, 3, 1, 2, 3, 2, 3, 2, 0, 2,\n",
              "       3, 3, 2, 1, 3, 0, 0, 2, 3, 3, 2, 2, 3, 0, 1, 3, 3, 0, 1, 0, 1, 2,\n",
              "       3, 2, 1, 3, 0, 2, 2, 2, 0, 0, 1, 3, 1, 2, 2, 1, 3, 0, 3, 3, 0, 1,\n",
              "       2, 2, 0, 3, 3, 2, 2, 1, 1, 2, 2, 0, 0, 3, 2, 2, 0, 3, 0, 1, 2, 0,\n",
              "       0, 0, 3, 1, 0, 3, 3, 0, 2, 0, 1, 0, 2, 0, 0, 1, 1, 1, 3, 2, 2, 1,\n",
              "       0, 3, 1, 1, 1, 3, 3, 2, 2, 1, 3, 1, 1, 1, 3, 0, 3, 2, 2, 2, 3, 3,\n",
              "       3, 0, 1, 0, 1, 3, 3, 1, 2, 0, 0, 3, 0, 0, 0, 2, 0, 1, 0, 2, 2, 3,\n",
              "       2, 0, 1, 2, 2, 2, 0, 1, 2, 1, 1, 0, 0, 2, 1, 2, 0, 0, 1, 2, 3, 0,\n",
              "       2, 0, 0, 0, 0, 1, 3, 1, 1, 3, 3, 0, 3, 3, 0, 1, 1, 2, 2, 3, 1, 0,\n",
              "       1, 0, 3, 3, 0, 1, 3, 2, 2, 3, 1, 0, 1, 2, 2, 3, 3, 3, 1, 0, 2, 2,\n",
              "       3, 0, 1, 3, 1, 1, 3, 1, 2, 3, 3, 0, 1, 2, 3, 2, 1, 0, 2, 2, 1, 0,\n",
              "       2, 1, 0, 2, 0, 1, 2, 1, 3, 1, 1, 2, 1, 0, 2, 3, 2, 3, 1, 1, 1, 2,\n",
              "       3, 2, 2, 1, 2, 0, 3, 1, 0, 0, 0, 1, 0, 3, 2, 2, 3, 3, 3, 3, 2, 2,\n",
              "       0, 2, 2, 2, 1, 2, 2, 2, 3, 1, 1, 0, 2, 3])"
            ]
          },
          "metadata": {},
          "execution_count": 147
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "output"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DbycsZQJKJkE",
        "outputId": "2e5a1d39-dc81-417a-ba94-685cec7b3079"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'test-topic-document-matrix': array([[0.01993886, 0.        , 0.        , ..., 0.98156393, 0.03036368,\n",
              "         0.        ],\n",
              "        [0.        , 0.0677283 , 0.        , ..., 0.        , 0.        ,\n",
              "         0.        ],\n",
              "        [0.98006114, 0.06097251, 1.        , ..., 0.        , 0.96963632,\n",
              "         0.1148065 ],\n",
              "        [0.        , 0.87129919, 0.        , ..., 0.01843607, 0.        ,\n",
              "         0.8851935 ]]),\n",
              " 'topic-document-matrix': array([[0.26720211, 0.        , 0.        , ..., 0.14275732, 0.90111454,\n",
              "         0.09516059],\n",
              "        [0.01187323, 1.        , 1.        , ..., 0.21519976, 0.        ,\n",
              "         0.00552508],\n",
              "        [0.60932501, 0.        , 0.        , ..., 0.64204292, 0.        ,\n",
              "         0.84844574],\n",
              "        [0.11159965, 0.        , 0.        , ..., 0.        , 0.09888546,\n",
              "         0.0508686 ]]),\n",
              " 'topic-word-matrix': array([[1.31396175e-04, 0.00000000e+00, 1.51972218e-03, ...,\n",
              "         0.00000000e+00, 0.00000000e+00, 0.00000000e+00],\n",
              "        [9.64183888e-06, 0.00000000e+00, 0.00000000e+00, ...,\n",
              "         0.00000000e+00, 0.00000000e+00, 0.00000000e+00],\n",
              "        [1.39583842e-05, 1.17751421e-04, 2.36863735e-04, ...,\n",
              "         1.01127608e-11, 0.00000000e+00, 0.00000000e+00],\n",
              "        [0.00000000e+00, 8.99492668e-06, 2.88786052e-04, ...,\n",
              "         0.00000000e+00, 4.20614851e-10, 8.08072008e-10]]),\n",
              " 'topics': [['cyclone',\n",
              "   'debbie',\n",
              "   'ex',\n",
              "   'queensland',\n",
              "   'school',\n",
              "   'tropical',\n",
              "   'wildfire',\n",
              "   'rain',\n",
              "   'california',\n",
              "   'australia'],\n",
              "  ['earthquake',\n",
              "   'flood',\n",
              "   'felt',\n",
              "   'fire',\n",
              "   'like',\n",
              "   'amp',\n",
              "   'feel',\n",
              "   'one',\n",
              "   'please',\n",
              "   'california'],\n",
              "  ['wildfire',\n",
              "   'california',\n",
              "   'flood',\n",
              "   'smoke',\n",
              "   'canada',\n",
              "   'fort',\n",
              "   'mcmurray',\n",
              "   'canadian',\n",
              "   'northern',\n",
              "   'alberta'],\n",
              "  ['flood',\n",
              "   'got',\n",
              "   'water',\n",
              "   'debbie',\n",
              "   'cyclone',\n",
              "   'go',\n",
              "   'people',\n",
              "   'via',\n",
              "   'get',\n",
              "   'flash']]}"
            ]
          },
          "metadata": {},
          "execution_count": 148
        }
      ]
    }
  ]
}